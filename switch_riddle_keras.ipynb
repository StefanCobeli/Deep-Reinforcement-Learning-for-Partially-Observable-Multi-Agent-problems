{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Switch Riddle\n",
    "\n",
    "Architecture, methodology and notations inspired from the paper [Learning to Communicate to Solve Riddles with Deep Distributed Recurrent Q-Networks](https://www.semanticscholar.org/paper/Learning-to-Communicate-to-Solve-Riddles-with-Deep-Foerster-Assael/52cb696af18aad0383770071d150137c39404edf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action encodings:\n",
    "  - 1, 0 = None;\n",
    "  - 0, 1 = Tell.\n",
    "  \n",
    "Message encodings:\n",
    "  - 1, 0 = Turn **Off** the bulb;\n",
    "  - 0, 1 = Turn __On__ the bulb.\n",
    "\n",
    "Observation encodings:\n",
    "  - 1, 0 = Not in the room;\n",
    "  - 0, 1 = In the room.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_max_num_episodes(number_of_agents):\n",
    "    return number_of_agents * 4 - 6\n",
    "\n",
    "number_of_agents = 3\n",
    "max_num_episodes = get_max_num_episodes(number_of_agents)\n",
    "\n",
    "rnn_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Add, Embedding, LSTM, Dense\n",
    "from keras.layers import Reshape, Concatenate\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Nadam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import GRU, Flatten\n",
    "\n",
    "def generate_model(number_of_agents, rnn_size = 128):\n",
    "    def get_max_num_episodes(number_of_agents):\n",
    "        return number_of_agents * 4 - 6\n",
    "    max_num_episodes = get_max_num_episodes(number_of_agents)\n",
    "    \n",
    "    bias_initializer = RandomNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "    activation = 'tanh'#Activation('tanh')#LeakyReLU()\n",
    "    \n",
    "    #o^k_t #in or out of the room;\n",
    "    #0-out; 1-in.\n",
    "    #could be 0 1 or 1 0... \n",
    "    participation_inputs      = [Input(shape = (1,), dtype='float32', name='participation_input_' + str(i))\\\n",
    "                              for i in range(max_num_episodes)]\n",
    "\n",
    "    #m_{t-1} #Received message;\n",
    "    # 0 1 - On; 1 0 - Off, 0 0 - Null;\n",
    "    message_inputs            = [Input(shape = (2,), dtype='float32', name='message_input_' + str(i))\\\n",
    "                              for i in range(max_num_episodes)]\n",
    "    #Can add MLPs here with batch normalization, like in the article\n",
    "\n",
    "    #u^a_{t-1}  #Tell or None action #Better idea: #Turn On or Tun Off;\n",
    "    # 0 1 - On; 1 0 - Off, 0 0 - Null;\n",
    "    last_action_inputs        = [Input(shape = (2,), dtype='float32', name='last_action_input_' + str(i))\\\n",
    "                              for i in range(max_num_episodes)]\n",
    "\n",
    "    #a. One hot encoding of the agent's index.\n",
    "    # index_inputs              = [Input(shape = (number_of_agents,), dtype='float32', name='index_input_' + str(i))\\\n",
    "    #                           for i in range(max_num_episodes)]\n",
    "\n",
    "    index_input              = Input(shape = (number_of_agents,), dtype='float32', name='index_input')\n",
    "    \n",
    "    \n",
    "    #o^k_t #in or out of the room;\n",
    "    #0-out; 1-in.\n",
    "    #could be 0 1 or 1 0... \n",
    "    participation_embeddings      = [Dense(128, activation=activation, dtype='float32')(o) for o in participation_inputs]\n",
    "\n",
    "    #m_{t-1} #Received message;\n",
    "    # 0 1 - On; 1 0 - Off, 0 0 - Null;\n",
    "    message_embeddings           = [Dense(128, activation=activation, dtype='float32')(Activation('tanh')(m))\\\n",
    "                                    for m in message_inputs]#Activation('sigmoid')(m)\n",
    "    #Can add MLPs here with batch normalization, like in the article\n",
    "\n",
    "    #u^a_{t-1}  #Tell or None action #Better idea: #Turn On or Tun Off;\n",
    "    # 0 1 - On; 1 0 - Off, 0 0 - Null;\n",
    "    last_action_embeddings       = [Dense(128, activation=activation, dtype='float32')(u) for u in last_action_inputs]\n",
    "\n",
    "    #a. One hot encoding of the agent's index.\n",
    "    # index_embeddings             = [Dense(128, dtype='float32')(a) for a in index_inputs]\n",
    "\n",
    "    index_embedding             = Dense(128, activation=activation, dtype='float32')(index_input)\n",
    "    \n",
    "    #z^a_t\n",
    "    recurrent_inputs = [Add()([o, m, u, index_embedding]) for \\\n",
    "                       (((o, m), u)) in zip(zip(participation_embeddings,\\\n",
    "                                                       message_embeddings),\\\n",
    "                                                   last_action_embeddings)]\n",
    "\n",
    "\n",
    "    recurrent_input = Concatenate(axis=1)(recurrent_inputs)\n",
    "    \n",
    "    #h^a_{1, t}\n",
    "    recurrent_output_1 = (GRU(rnn_size, return_sequences=True)(Reshape((-1, 128))(recurrent_input)))\n",
    "    recurrent_input_2  = recurrent_output_1\n",
    "    \n",
    "    #h^a_{2, t}\n",
    "    recurrent_output_2 = GRU(rnn_size)(Reshape((-1, 128))(recurrent_input_2))#recurrent_input))#\n",
    "    recurrent_output_2\n",
    "\n",
    "    dense_1 = Dense(rnn_size, activation=activation)(recurrent_output_2)\n",
    "    dense_2 = Dense(rnn_size,  activation=activation)(dense_1)\n",
    "    #Q values for messages and for actions\n",
    "    output  = Dense(4,  activation=activation)(dense_2)\n",
    "\n",
    "    \n",
    "    \n",
    "    model = Model(inputs=participation_inputs + message_inputs + last_action_inputs + [index_input],\\\n",
    "              outputs=[output])\n",
    "    \n",
    "    \n",
    "    rmsprop = Nadam(lr=5 * 10 ** (-4), beta_1=0.95, beta_2=0.999, schedule_decay=0.004)\n",
    "    model.compile(loss='mean_squared_error', optimizer=rmsprop, )\n",
    "\n",
    "    return model\n",
    "\n",
    "model = generate_model(number_of_agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "message_input_0 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_1 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_2 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_3 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_4 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_5 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_6 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_7 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_8 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "message_input_9 (InputLayer)    (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_0 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 2)            0           message_input_0[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_0 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "index_input (InputLayer)        (None, 4)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_1 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 2)            0           message_input_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_1 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_2 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 2)            0           message_input_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_2 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_3 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 2)            0           message_input_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_3 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_4 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 2)            0           message_input_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_4 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_5 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 2)            0           message_input_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_5 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_6 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 2)            0           message_input_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_6 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_7 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 2)            0           message_input_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_7 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_8 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 2)            0           message_input_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_8 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "participation_input_9 (InputLay (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 2)            0           message_input_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "last_action_input_9 (InputLayer (None, 2)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 128)          256         participation_input_0[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 128)          384         activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 128)          384         last_action_input_0[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_53 (Dense)                (None, 128)          640         index_input[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 128)          256         participation_input_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 128)          384         activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 128)          384         last_action_input_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          256         participation_input_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 128)          384         activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_45 (Dense)                (None, 128)          384         last_action_input_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128)          256         participation_input_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 128)          384         activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_46 (Dense)                (None, 128)          384         last_action_input_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 128)          256         participation_input_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_37 (Dense)                (None, 128)          384         activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_47 (Dense)                (None, 128)          384         last_action_input_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          256         participation_input_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 128)          384         activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_48 (Dense)                (None, 128)          384         last_action_input_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          256         participation_input_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 128)          384         activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_49 (Dense)                (None, 128)          384         last_action_input_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          256         participation_input_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 128)          384         activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_50 (Dense)                (None, 128)          384         last_action_input_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 128)          256         participation_input_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 128)          384         activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_51 (Dense)                (None, 128)          384         last_action_input_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 128)          256         participation_input_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 128)          384         activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_52 (Dense)                (None, 128)          384         last_action_input_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 128)          0           dense_23[0][0]                   \n",
      "                                                                 dense_33[0][0]                   \n",
      "                                                                 dense_43[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 128)          0           dense_24[0][0]                   \n",
      "                                                                 dense_34[0][0]                   \n",
      "                                                                 dense_44[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 128)          0           dense_25[0][0]                   \n",
      "                                                                 dense_35[0][0]                   \n",
      "                                                                 dense_45[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 128)          0           dense_26[0][0]                   \n",
      "                                                                 dense_36[0][0]                   \n",
      "                                                                 dense_46[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 128)          0           dense_27[0][0]                   \n",
      "                                                                 dense_37[0][0]                   \n",
      "                                                                 dense_47[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 128)          0           dense_28[0][0]                   \n",
      "                                                                 dense_38[0][0]                   \n",
      "                                                                 dense_48[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 128)          0           dense_29[0][0]                   \n",
      "                                                                 dense_39[0][0]                   \n",
      "                                                                 dense_49[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 128)          0           dense_30[0][0]                   \n",
      "                                                                 dense_40[0][0]                   \n",
      "                                                                 dense_50[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 128)          0           dense_31[0][0]                   \n",
      "                                                                 dense_41[0][0]                   \n",
      "                                                                 dense_51[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 128)          0           dense_32[0][0]                   \n",
      "                                                                 dense_42[0][0]                   \n",
      "                                                                 dense_52[0][0]                   \n",
      "                                                                 dense_53[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 1280)         0           add_7[0][0]                      \n",
      "                                                                 add_8[0][0]                      \n",
      "                                                                 add_9[0][0]                      \n",
      "                                                                 add_10[0][0]                     \n",
      "                                                                 add_11[0][0]                     \n",
      "                                                                 add_12[0][0]                     \n",
      "                                                                 add_13[0][0]                     \n",
      "                                                                 add_14[0][0]                     \n",
      "                                                                 add_15[0][0]                     \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 10, 128)      0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 10, 128)      98688       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 10, 128)      0           gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 128)          98688       reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_54 (Dense)                (None, 128)          16512       gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_55 (Dense)                (None, 128)          16512       dense_54[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 4)            516         dense_55[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 241,796\n",
      "Trainable params: 241,796\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generate_model(4).summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find if there is an available GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpu:0'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Data set creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 3, 3],\n",
       "       [3, 3, 3, 1, 1, 2],\n",
       "       [1, 3, 3, 2, 1, 3],\n",
       "       [2, 3, 3, 1, 2, 1],\n",
       "       [1, 1, 1, 2, 1, 1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def draw_episode(number_of_agents):\n",
    "    '''return an array, with indexes of the sampled prisoners, of length max_num_episodes'''\n",
    "    max_num_episodes = get_max_num_episodes(number_of_agents)\n",
    "    return [np.random.randint(1, number_of_agents + 1) for i in range(max_num_episodes)]\n",
    "\n",
    "draw_episode(3)\n",
    "\n",
    "def draw_episodes_batch(number_of_agents, batch_size):\n",
    "    '''return an array, of length batch_size, of arrays, with 1's and 2's, of length number_of_agents'''\n",
    "    max_num_episodes = get_max_num_episodes(number_of_agents)\n",
    "    return np.random.randint(1, number_of_agents + 1, size=(batch_size, max_num_episodes))\n",
    "\n",
    "draw_episodes_batch(number_of_agents=3, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'index_input': array([[ 1.,  0.]]),\n",
       " 'last_action_input_0': array([[ 0.,  0.]]),\n",
       " 'last_action_input_1': array([[ 0.,  0.]]),\n",
       " 'message_input_0': array([[ 0.,  0.]]),\n",
       " 'message_input_1': array([[ 0.,  0.]]),\n",
       " 'participation_input_0': array([[ 0.]]),\n",
       " 'participation_input_1': array([[ 0.]])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_agent_first_input(number_of_agents, agent_idx):\n",
    "    '''agent_idx starts from 1 and goes to number_of_agents inclusively'''\n",
    "    max_num_episodes = get_max_num_episodes(number_of_agents)\n",
    "    input_prefixes = [\"participation_input_\", \"message_input_\", \"last_action_input_\"]\n",
    "    input_dims     = [1, 2, 2]\n",
    "    pref_dim_pairs = {p : d for p, d in zip(input_prefixes, input_dims)}\n",
    "    \n",
    "    \n",
    "    from functools import reduce\n",
    "    input_names = reduce(lambda x,y: x + y, [list(map(lambda x: x + str(i), input_prefixes))\\\n",
    "                                             for i in range(max_num_episodes)])\n",
    "    \n",
    "    \n",
    "    \n",
    "    inputs                 = {name: np.zeros((1, pref_dim_pairs[name[:-1]])) for name in input_names}\n",
    "    inputs[\"index_input\"]  = np.reshape(np.eye(number_of_agents)[agent_idx-1], (-1, number_of_agents))#((1,number_of_agents))[:-1]\n",
    "    return inputs\n",
    "\n",
    "mock_input= generate_agent_first_input(3, 2)\n",
    "# mock_input = generate_empty_inputs(2)\n",
    "# model.predict(mock_input)\n",
    "generate_agent_first_input(2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#method to be tested and to be added edge cases\n",
    "\n",
    "def generate_agent_input(time_step, previous_input, received_message, last_action):\n",
    "    '''\n",
    "    time_step starts from 0 and goes until max_num_episodes-1 inclusively.\n",
    "    episode:             the agent order in the room;\n",
    "    agent_idx:        the agent for which the input is generated (indexed from 1);\n",
    "    received_message: list with two elements indicating the postion of the bulb;\n",
    "    last_action:      list with two elements indicating the message sent at time_step - 1.\n",
    "\n",
    "    '''\n",
    "    #useless parameters: episode, agent_idx, \n",
    "    \n",
    "    new_input = previous_input\n",
    "    \n",
    "    new_input[\"participation_input_\" + str(time_step)][0] = 1\n",
    "    new_input['message_input_' + str(time_step)][0] = received_message\n",
    "    #last_action = previous_input[\"last_action_input_\" + str(time_step - 1)][0] if time_step > 0 else [0, 0] \n",
    "    \n",
    "    new_input[\"last_action_input_\" + str(time_step)][0] = last_action\n",
    "    \n",
    "    return new_input\n",
    "\n",
    "episode    = draw_episode(2)\n",
    "mock_input = generate_agent_first_input(3, 2)\n",
    "# generate_agent_input(time_step=5,\\\n",
    "#                      previous_input=mock_input,\\\n",
    "#                      received_message=[0, 1],\\\n",
    "#                      last_action=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def generate_batch_input(time_step, previous_inputs, received_messages, last_actions):\n",
    "    '''\n",
    "    time_step:         starts from 0 and goes until max_num_episodes-1 inclusively;\n",
    "    received_messages: list of lists with two elements indicating the postion of the bulb;\n",
    "    previous_inputs:   list of previous_input;\n",
    "    last_actions:      list of lists with two elements indicating the message sent at time_step - 1.\n",
    "\n",
    "    \n",
    "    calls generate_agent_input() for each pair from zip(previous_inputs, received_messages, last_actions)\n",
    "    '''\n",
    "    from functools import reduce\n",
    "    new_inputs_list = [generate_agent_input(time_step, p, r, l) for ((p, r), l) in zip(zip(previous_inputs,\\\n",
    "                                                                                      received_messages),\\\n",
    "                                                                                 last_actions)]\n",
    "    new_inputs = {}\n",
    "    for name in new_inputs_list[0]:\n",
    "        new_inputs[name] = reduce(lambda x, y: np.vstack((x, y)), [inp[name] for inp in new_inputs_list]) \n",
    "    return new_inputs, new_inputs_list\n",
    "\n",
    "episode    = draw_episodes_batch(3, 2)\n",
    "\n",
    "mock_batch = generate_batch_input(1, [mock_input, mock_input], [[1,0], [0,1]], [[1,0], [1,0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.09314222, -0.04448696,  0.05284136,  0.05662699],\n",
       "       [ 0.09314222, -0.04448696,  0.05284136,  0.05662699]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(mock_batch[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flow of data through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.  ,  0.25]), array([ 0.5 ,  0.75]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def action_selector(predictions, epsilon=1, test_mode=False):\n",
    "    '''predictions: np array with 4 elements\n",
    "    returns pair action, message\n",
    "    \n",
    "    e.g. [.2, .9, .89, .01]\n",
    "    First two are for indicating Tell or Not;\n",
    "    Last two are for turning On or Off the Switch \n",
    "    '''\n",
    "    action  = np.zeros(2)#[0, 0]\n",
    "    message = np.zeros(2)#[0, 0]\n",
    "    \n",
    "    if test_mode == True:    \n",
    "        action[predictions[:2].argmax()]   = 1\n",
    "        message[predictions[2:4].argmax()] = 1    \n",
    "        return action, message\n",
    "    \n",
    "    action  = np.array([p for p in predictions[0:2]])\n",
    "    message = np.array([p for p in predictions[2:4]])\n",
    "    if np.random.rand() < epsilon:\n",
    "        choice = np.random.randint(2)\n",
    "        action[choice]     = 1\n",
    "        action[choice - 1] = predictions[:2][choice - 1]\n",
    "    if np.random.rand() < epsilon:\n",
    "        choice = np.random.randint(2)\n",
    "        message[choice]     = 1\n",
    "        message[choice - 1] = predictions[2:4][choice - 1]\n",
    "    return action, message\n",
    "    \n",
    "action_selector(np.arange(4) / 4, .1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_episode_description(number_of_agents, batch_size):\n",
    "    #Intialization of one episode batch:\n",
    "    episode_batch    = draw_episodes_batch(number_of_agents, batch_size)\n",
    "    #who visited the room in each episode of the batch\n",
    "    visits   = [[0] * number_of_agents for i in range(batch_size)]\n",
    "    #which episode from the batch ended\n",
    "    ended    = [0] * batch_size\n",
    "    #the position of the bulb in each episode #this are the received messages\n",
    "    #states   = [[0, 0] for i in range(batch_size)] #can be deduced from per_step_prediction\n",
    "    reward  = [0] * batch_size\n",
    "    \n",
    "    return episode_batch, visits, ended, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_episode_input_holder(number_of_agents, batch_size):\n",
    "    #generate first inputs for all agents in all the episodes\n",
    "    all_prev_inputs = [[generate_agent_first_input(number_of_agents, agent_idx=a + 1)\\\n",
    "                        for a in range(number_of_agents)] \\\n",
    "                       for ep in range(batch_size)]\n",
    "    \n",
    "    #rember all inputs for the backward pass\n",
    "    per_step_inputs = [[] for i in range(batch_size)]\n",
    "    #remeber all predictions. They will have a one on one corespondence with \"per_step_inputs\"\n",
    "    per_step_predictions = [[] for i in range(batch_size)]\n",
    "    \n",
    "    return all_prev_inputs, per_step_inputs, per_step_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "number_of_agents = 4\n",
    "max_num_episodes = get_max_num_episodes(number_of_agents)\n",
    "model = generate_model(number_of_agents)\n",
    "batch_size   = 32\n",
    "num_episodes = 20000\n",
    "epsilon = .2\n",
    "gamma = 1\n",
    "winning_percentages = []\n",
    "# average_saved_agents = [number_of_agents / 2] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ETA: 0:0:0.             Percentage of winning episodes, after 20000, out of 20000 (100.00%), episodes is 0.75."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import copy\n",
    "import time\n",
    "from functools import reduce\n",
    "\n",
    "eta_per_eps = []\n",
    "for episode in range(num_episodes):\n",
    "    #################\n",
    "    #Initializations:\n",
    "    ep_start_time = time.time()\n",
    "    episode_batch, visits, ended, reward = generate_episode_description(number_of_agents, batch_size)\n",
    "    all_prev_inputs, per_step_inputs, per_step_predictions = generate_episode_input_holder(number_of_agents, batch_size)\n",
    "    \n",
    "    ############\n",
    "    #1.Prepare inputs;\n",
    "    #2.Forward pass;\n",
    "    #3.Validate predictions;\n",
    "    #4.Backward pass.\n",
    "    for step in range(max_num_episodes):\n",
    "        if sum(ended) == batch_size:\n",
    "            break\n",
    "        ##################\n",
    "        #1.Prepare inputs:\n",
    "        #which agents are in the room at time \"step\"\n",
    "        \n",
    "        active_episodes     = [i for i in range(batch_size) if ended[i] == 0]\n",
    "        #which agents are in the room at time \"step\"\n",
    "        selected_agents     = [episode_batch[ep][step] for ep in active_episodes]        \n",
    "        #take previous inputs of the selected agents. !Remember that the agents are idexed starting with 1!\n",
    "        previous_inputs   = [all_prev_inputs[a][s - 1] \\\n",
    "                             for (a,s) in zip(active_episodes, selected_agents)]\n",
    "\n",
    "        #if the same agent entered the room the previous step:\n",
    "        #then the last action is what he predicted (On or Off), else [0, 0]. \n",
    "        last_actions      = [action_selector(np.hstack(per_step_predictions[i][-1]), test_mode=True)[1]\\\n",
    "                             if step > 0 and episode_batch[i][step-1] == episode_batch[i][step]\\\n",
    "                             else [0, 0]\\\n",
    "                             for i in range(batch_size)\\\n",
    "                             if i in active_episodes]\n",
    "        #what is the position of the bulb. At step==0, bulb is Off([1,0])\n",
    "        received_messages = [[1, 0] if step == 0 \\\n",
    "                             else action_selector(np.hstack(per_step_predictions[i][-1]), test_mode=True)[1]\\\n",
    "                             for i in range(batch_size)\\\n",
    "                             if i in active_episodes]\n",
    "        #generate inputs for the DQN \n",
    "        inputs_batch, inputs_list = generate_batch_input(time_step=step,\\\n",
    "                                      previous_inputs=previous_inputs,\\\n",
    "                                      received_messages=received_messages,\\\n",
    "                                      last_actions=last_actions)\n",
    "        ###########\n",
    "        #2.Forward:\n",
    "        #predict actions\n",
    "        outputs = model.predict(inputs_batch, batch_size=len(active_episodes))\n",
    "\n",
    "        #update previous_inputs \n",
    "        for ep in range(len(active_episodes)):\n",
    "            \n",
    "            idx_in_batch  = active_episodes[ep]\n",
    "            idx_in_active = ep\n",
    "        \n",
    "            #add the new visitor in visits\n",
    "            visits[idx_in_batch][selected_agents[ep] - 1] = 1\n",
    "            #update all previous inputs\n",
    "            all_prev_inputs[idx_in_batch][selected_agents[ep] - 1] = copy.deepcopy(inputs_list[ep])\n",
    "            #remeber inputs and predictions respectively\n",
    "            per_step_inputs[idx_in_batch].append(copy.deepcopy(inputs_list[ep]))\n",
    "            prediction = action_selector(outputs[ep], epsilon)\n",
    "            per_step_predictions[idx_in_batch].append(copy.deepcopy(prediction))            \n",
    "        \n",
    "            ##############\n",
    "            #3.Validation:\n",
    "            #end episodes which just used \"Tell\"\n",
    "            #validate the just ended episodes\n",
    "            if prediction[0].argmax() == 1:\n",
    "                #then the episode has ended\n",
    "                ended[ep] = 1\n",
    "                if sum(visits[ep]) == number_of_agents:\n",
    "                    reward[ep] = 1\n",
    "                else:\n",
    "                    reward[ep] = -1\n",
    "    \n",
    "    ##################\n",
    "    #4. Backward pass:\n",
    "    for step in np.arange(max_num_episodes - 1, -1, -1):\n",
    "        targets = []\n",
    "        inputs  = {}\n",
    "        input_list = []\n",
    "        target_list = []\n",
    "        \n",
    "        active_episodes = [ep for ep in np.arange(batch_size)\\\n",
    "                           if len(per_step_inputs[ep]) > step]\n",
    "        if len(active_episodes) == 0:\n",
    "            continue\n",
    "        input_list  = [copy.deepcopy(per_step_inputs[ep][step]) for ep in active_episodes]\n",
    "        target_list = [copy.deepcopy(per_step_predictions[ep][step]) for ep in active_episodes]\n",
    "        \n",
    "        for ep in active_episodes:\n",
    "            idx_in_active = active_episodes.index(ep)\n",
    "            \n",
    "            action  = target_list[idx_in_active][0]\n",
    "            message = target_list[idx_in_active][1]\n",
    "                        \n",
    "            if len(per_step_inputs[ep]) == (step + 1):\n",
    "                action[action.argmax()]   = reward[ep]\n",
    "                message[message.argmax()] = reward[ep]\n",
    "            else:\n",
    "                action[action.argmax()]   = np.max(per_step_predictions[ep][step][0])\n",
    "                message[message.argmax()] = np.max(per_step_predictions[ep][step][1])\n",
    "            \n",
    "            targets.append(np.hstack([action, message]))\n",
    "        \n",
    "        for name in inputs_list[0]:\n",
    "            inputs[name] = reduce(lambda x, y: np.vstack((x, y)), [inp[name] for inp in input_list])\n",
    "        \n",
    "        targets = np.array(targets)\n",
    "        model.fit(inputs, targets, batch_size=len(active_episodes), verbose=0)\n",
    "    \n",
    "    winning_percentages.append(len([r for r in reward if r == 1])/batch_size)\n",
    "    eta_per_eps.append(time.time() - ep_start_time)\n",
    "    if(episode % 20 == 19):\n",
    "        winning_episode_percentage = sum(winning_percentages[-20:]) / 20\n",
    "        training_percentage = (episode + 1) / num_episodes * 100\n",
    "        \n",
    "        sys.stdout.write(\"\\r                         Percentage of winning episodes, after {0:d}, out of {1:d} ({2:.2f}%), episodes is {3:.2f}.\"\\\n",
    "              .format(episode + 1, num_episodes, training_percentage, winning_episode_percentage))\n",
    "        \n",
    "        eta_seconds = int(((sum(eta_per_eps[-30:]) / 30) * (num_episodes - episode)))\n",
    "        \n",
    "        eta_hours   = eta_seconds // 3600\n",
    "        eta_minutes = (eta_seconds % 3600) // 60\n",
    "        eta_seconds = eta_seconds % 60\n",
    "        sys.stdout.write(\"\\r ETA: {0:0d}:{1:0d}:{2:0d}.\".format(eta_hours, eta_minutes, eta_seconds))\n",
    "        \n",
    "        \n",
    "    if(episode % 100 == 99):\n",
    "        epsilon = max(.01, epsilon - .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"results/statistics/switch_riddle/switch_{0:d}_winning_percentages\".format(number_of_agents)\\\n",
    "           , winning_percentages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot preliminary results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(1)\n",
    "\n",
    "def plot_performace_with_confidence(number_of_agents, winning_percentages):\n",
    "    df = pd.DataFrame(winning_percentages)\n",
    "\n",
    "    ma = df.rolling(1000).mean()\n",
    "    mstd = 2 * df.rolling(1000).std()\n",
    "    figure = plt.figure(figsize=(5, 3), linewidth=.5, dpi= 120, facecolor = 'white')\n",
    "\n",
    "    plt.title(str(number_of_agents) + \" prisoners.\")\n",
    "    plt.ylim(.0, 1)\n",
    "    # plt.yticks(np.arange(.5, 1.01, .1))\n",
    "    plt.grid(color='k', linewidth=.5, linestyle=':')\n",
    "    # plt.\n",
    "    # plt.xticks(np.arange(20000, 100001, 20000), [str(i) + 'k' for i in range(20, 101, 20)])\n",
    "    ax = plt.plot(ma, linewidth=2)\n",
    "    plt.fill_between(mstd.index, (ma-mstd)[0], (ma+mstd)[0], color='b', alpha=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_performace_with_confidence(number_of_agents, winning_percentages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
